<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Winder</title>
    <link rel="stylesheet" href="/assets/css/styles.css">
    <link rel="shortcut icon" href="">
    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link href="https://fonts.googleapis.com/css2?family=Open+Sans&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet">
    <link rel="apple-touch-icon" sizes="180x180" href="/assets/favicon/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/assets/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon/favicon-16x16.png">
  <link rel="manifest" href="/assets/favicon/site.webmanifest">
    <!--[if lt IE 9]>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js"></script>
    <![endif]-->
  </head>
  <base target="_blank">
  <body>
    <div>
      <div class="wrapper">
        <h1 style="font-family: 'Lato', sans-serif;">
          
            <img src="/assets/img/winder_logo.svg" width="40px" style="vertical-align:middle"/>
          
          <span style="vertical-align:middle; color: #7354f3;"/>Winder</span>
        </h1>
        <h4>Linking Speech and Visual Objects to Support Communication in Asynchronous Collaboration</h4>
        <div class="authors-wrapper">
        
          <div class="author-container">
            <div class="author-image">
              <img src="/assets/img/taesoo.jpeg"/>
            </div>
            <p>
            
              <a href="https://taesookim.com">
                Tae Soo Kim
              </a>
            
            </p>
            <p>
              KAIST
            </p>
          </div>
        
          <div class="author-container">
            <div class="author-image">
              <img src="/assets/img/seungsu.jpg"/>
            </div>
            <p>
            
              Seungsu Kim
            
            </p>
            <p>
              KAIST
            </p>
          </div>
        
          <div class="author-container">
            <div class="author-image">
              <img src="/assets/img/yoonseo.png"/>
            </div>
            <p>
            
              <a href="https://yoonseochoi.com">
                Yoonseo Choi
              </a>
            
            </p>
            <p>
              KAIST
            </p>
          </div>
        
          <div class="author-container">
            <div class="author-image">
              <img src="/assets/img/juho.jpg"/>
            </div>
            <p>
            
              <a href="https://juhokim.com">
                Juho Kim
              </a>
            
            </p>
            <p>
              KAIST
            </p>
          </div>
        
        </div>
      </div>
    </div>
    <div class="wrapper">
      <hr/>
      
      <div class="video-wrapper">
        <iframe src="https://drive.google.com/file/d/1Y4-UP6VrjVat2m0-qhxUcFvSX6xzATVt/preview" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
      </div>
      <hr/>
      
      <h2 id="abstract">Abstract</h2>

<p>Team members commonly collaborate on visual documents remotely and asynchronously. Particularly, students are frequently restricted to this setting as they often do not share work schedules or physical workspaces. As communication in this setting has delays and limits the main modality to text, members exert more effort to reference document objects and understand others’ intentions. We propose <span style="color:#7354f3">Winder</span>, a Figma plugin that addresses these challenges through <em>linked tapes</em>—multimodal comments of clicks and voice. Bidirectional links between the clicked-on objects and voice recordings facilitate understanding tapes: selecting objects retrieves relevant recordings, and playing recordings highlights related objects. By periodically prompting users to produce tapes, <span style="color:#7354f3">Winder</span> preemptively obtains information to satisfy potential communication needs. Through a five-day study with eight teams of three, we evaluated the system’s impact on teams asynchronously designing graphical user interfaces. Our findings revealed that producing linked tapes could be as lightweight as face-to-face (F2F) interactions while transmitting intentions more precisely than text. Furthermore, with preempted tapes, teammates coordinated tasks and invited members to build on each others’ work.</p>

<hr />

<h2 id="system">System</h2>

<p>In <span style="color:#7354f3">Winder</span>, users send <em>linked tapes</em>, which are recordings of their voice and clicks on objects on the UI design. The system generates bidirectional links between voice snippets and clicked-on objects to support navigation and understanding the receiver side.</p>

<p>The main components of the system’s interface are (a) the top bar, (b) the list of linked tapes, and (c) the transcript space.</p>

<p class="center sys-img"><img src="/assets/img/winder_main.png" alt="Winder next to the design for a screen of a mobile application" /></p>

<h3 id="object-highlighting-on-voice-playback">Object Highlighting on Voice Playback</h3>

<p>When the user plays a tape, <span style="color:#7354f3">Winder</span> Winder displays the version of the document when the tape was recorded, and plays the voice audio while highlighting objects as they were clicked during recording.</p>

<p class="center sys-img"><img src="/assets/img/winder_highlight.png" alt="An image of a salad in the UI design is highlighted while a recording appears to be playing in Winder." /></p>

<h3 id="inline-thumbnail-images-on-voice-transcripts">Inline Thumbnail Images on Voice Transcripts</h3>

<p class="img-left"><img src="/assets/img/winder_transcript.png" alt="A transcript of a voice recording is shown with inline thumbnail images of UI design objects." /></p>

<p class="text-right"><span style="color:#7354f3">Winder</span> provides automatic transcripts of the voice recordings (generated through speech-to-text). On the transcript, it embeds thumbnail images of the objects clicked during the recording inline with the words of the transcript.</p>

<h3 id="object-based-search-of-voice-recordings">Object-based Search of Voice Recordings</h3>

<p>If the user clicks on an object in the UI design, <span style="color:#7354f3">Winder</span> retrieves all tapes in which that object was selected. For each tape, the segment of the tape’s transcript during which the object had been clicked on is shown.</p>

<p class="center sys-img"><img src="/assets/img/winder_search.png" alt="A gray rectangle is clicked in the UI design. In Winder, a list of tapes shows a short snippets from transcripts and thumbnails of the gray rectangle." /></p>

<hr />

<h2 id="results">Results</h2>

<p>Tapes recorded by participants in a five-day user study were analyzed and categorized. The results showed that participants used <span style="color:#7354f3">Winder</span> for a variety of purposes—with most tapes used for “Describing” or “Justifying” design choices, or “Coordinating” work within a team.</p>

<p class="center sys-img"><img src="/assets/img/results_type.png" alt="Table showing descriptions and example snippets of each tape category. Additionally, the table shows the perentage of tapes that fit into that category." /></p>

<p>Participants mentioned how <span style="color:#7354f3">Winder</span> increased their shared understanding, motivated them to work, and made them feel as if they were co-present.</p>

<p class="center quote">T2M1: <em>“The recordings left behind by my group members helped clarify some of the misunderstandings or confusions that I had.”</em></p>

<p class="center quote">T1M2: <em>“Understanding [my team members] actions and intentions was fun somehow and made me work harder.”</em></p>

<p class="center quote">T5M2: <em>“With the voice recordings and the feature that showed what the users clicked on as they talked, it was as if we were working together.”</em></p>

<hr />

<h2 id="chi-2021-paper-camera-ready">CHI 2021 Paper (Camera-ready)</h2>

<p><a href="/papers/CHI2021___Winder___CameraReady.pdf">Link to the PDF</a></p>

<h2 id="bibtex">Bibtex</h2>
<pre>
@inproceedings{10.1145/3313831.3376390,
          author = {Yang, Saelyne and Lee, Changyoon and Shin, Hijung Valentina and Kim, Juho},
          title = {Snapstream: Snapshot-Based Interaction in Live Streaming for Visual Art},
          year = {2020},
          isbn = {9781450367080},
          publisher = {Association for Computing Machinery},
          address = {New York, NY, USA},
          url = {https://doi.org/10.1145/3313831.3376390},
          doi = {10.1145/3313831.3376390},
          booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
          pages = {1–12},
          numpages = {12},
          keywords = {live streaming, online interaction, chat interaction, context sharing},
          location = {Honolulu, HI, USA},
          series = {CHI ’20}
        }
</pre>

<hr />

<p class="logos"><a href="https://kixlab.org"><img src="/assets/img/kixlab_logo.png" alt="Logo of KIXLAB" /></a>
<a href="https://kaist.ac.kr"><img src="/assets/img/kaist_logo.png" alt="Logo of KAIST" /></a></p>

<p class="center acknowledgement">This research was supported by the <a href="https://kaist.ac.kr">KAIST</a> UP Program.</p>


    </div>
    
  </body>
</html>
